{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e6e21-93ec-4ee6-8abc-20bb17017b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyPRISMClimate\n",
    "#!pip install hydrofunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e054d680-5b98-4528-bf47-46d671eef09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from rasterio import plot, mask\n",
    "import glob\n",
    "import os\n",
    "from pyPRISMClimate import get_prism_dailys\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import geopandas as gpd\n",
    "import hydrofunctions as hf\n",
    "import xarray as xr\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba4777-ea14-4c9b-aad0-d737e098606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dem\n",
    "fork = 'nf'\n",
    "in_asc_string = f'./dem_or_shapefile/final_{fork}_30m.asc'\n",
    "out_gdal_string = f'./dem_or_shapefile/final_{fork}_30m.tif'\n",
    "EPSG_code = 26710\n",
    "dem_proj = f'EPSG:{EPSG_code}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f953405-bef9-4450-9ca0-4248ed252737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dem_src = rio.open(out_gdal_string)\n",
    "dem_array = dem_src.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f2d13-d677-4b0e-9da8-d5cc7538bf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(out_gdal_string):\n",
    "    !gdal_translate -of \"GTiff\" -a_srs EPSG:EPSG_code $in_asc_string $out_gdal_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7513ad9-bb6f-45b5-9258-b05ac0b1ca21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to download usgs stream data, basin\n",
    "def get_basin_data(gaugeID, start_date, end_date, sf_filepath, featureSource = 'nwissite'):\n",
    "    basin_url = f'https://labs.waterdata.usgs.gov/api/nldi/linked-data/{featureSource}/USGS-{gaugeID}/basin'\n",
    "    \n",
    "    # get shapefile of gauge basin\n",
    "    basin_gdf = gpd.read_file(basin_url)\n",
    "    \n",
    "    # get streamflow at gauge\n",
    "    streamflow = hf.NWIS(site=gaugeID, service='dv', start_date=start_date, end_date=end_date, file=sf_filepath)\n",
    "    streamflow_df = streamflow.df()\n",
    "    return basin_gdf, streamflow_df\n",
    "\n",
    "everson_gdf, everson_streamflow = get_basin_data(gaugeID = '12211200', start_date = '2021-11-10', end_date = '2021-12-10', sf_filepath = 'discharge_data/everson.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef03ce5-2039-4c32-a2c8-ce5a956c37ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, a = plt.subplots()\n",
    "everson_gdf.plot(facecolor = 'green', ax=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febbb1b0-0eb1-49cf-a5e8-988fde635dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get weather data\n",
    "def get_weather_for_watershed(start_date, end_date, destination, boundaries, varlist = ['ppt', 'tmean']):\n",
    "   # this function will help keep track of the variable being downloaded and the date\n",
    "    def get_variable_and_date(filename):\n",
    "        filename = filename.split('_')\n",
    "        variable, date = filename[-5], pd.to_datetime(filename[-2])\n",
    "        return variable, date\n",
    "        \n",
    "    # download prism data\n",
    "    for var in varlist:\n",
    "        files = get_prism_dailys(var, min_date = start_date, \n",
    "                                 max_date = end_date, dest_path = destination,\n",
    "                                 keep_zip=False)\n",
    "    \n",
    "        # makes a list of the weather files downloaded by above\n",
    "        prism_file_paths = glob.glob(os.path.join(destination, '*.bil'))\n",
    "        prism_file_paths.sort()\n",
    "    \n",
    "        #empty list of arrays\n",
    "        arrays = []\n",
    "    \n",
    "        for file in prism_file_paths:\n",
    "            # open file\n",
    "            weather_file = rio.open(file)\n",
    "        \n",
    "            # mask file by watershed extent\n",
    "            rio_mask_kwargs = {'filled':False, 'crop':True, 'indexes':1}\n",
    "            array, array_transform = rio.mask.mask(weather_file, everson_gdf.to_crs(weather_file.crs).geometry, \n",
    "                                               **rio_mask_kwargs)\n",
    "        \n",
    "            lon = []\n",
    "            lat = []\n",
    "        \n",
    "            # transform pixel positions to latitude and longitude for xarray coordinates using the affine transform\n",
    "            for i in range(array.shape[0]):\n",
    "                x, y = rio.transform.xy(array_transform, i, 0)\n",
    "                lon = np.append(lon, y)\n",
    "        \n",
    "            for j in range(array.shape[1]):\n",
    "                x, y = rio.transform.xy(array_transform, 0, j)\n",
    "                lat = np.append(lat, x)\n",
    "        \n",
    "            variable, date = get_variable_and_date(file)\n",
    "        \n",
    "            # turn array into xarray to accomodate more dimensions\n",
    "            array = xr.DataArray(array, \n",
    "                                 dims = ('x', 'y'), \n",
    "                                 coords = {'x': lon, 'y': lat})\n",
    "        \n",
    "            # add date dimension\n",
    "            array = array.expand_dims(dim = 'date')\n",
    "            array.coords['date'] = ('date', [date])\n",
    "        \n",
    "            # add variable dimension\n",
    "            #array = array.expand_dims(dim = 'variable')\n",
    "            #array.coords['variable'] = ('variable', [variable])\n",
    "        \n",
    "            arrays.append(array)\n",
    "        \n",
    "            # remove file (memory management), comment this line out if you'd like to preserve\n",
    "            os.remove(file)\n",
    "    \n",
    "        globals()[f'dataset_{variable}'] = xr.concat(arrays, 'date')\n",
    "    return dataset_ppt, dataset_tmean\n",
    "\n",
    "test_file_ppt, test_file_tmean = get_weather_for_watershed('2021-11-10', '2021-12-10', 'precip_data/', everson_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c2d3d-a8f1-479c-bf3a-a69aecc993be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file_ppt.isel(date=slice(0, 31, 1)).plot.imshow(col = 'date', col_wrap = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759d921-a8c5-412e-bed0-18f931fc64cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file_tmean.isel(date=slice(0, 31, 1)).plot.imshow(col = 'date', col_wrap = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0421c4e9-3396-40b4-9b07-958dc61e2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get infiltration data - potentially could put it together via gSSURGO or land use files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f2d33-ba34-4ac8-b246-bed326b6f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get SNOTEL data\n",
    "# ulmo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f00d84-eb07-4b69-9939-62368b3290ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
